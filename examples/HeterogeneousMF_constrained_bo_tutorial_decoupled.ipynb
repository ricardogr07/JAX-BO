{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "from jax import random, vmap\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from pyDOE import lhs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "from jaxbo.models import MultipleIndependentHeterogeneousMFGP\n",
    "from jaxbo.utils import normalize_HeterogeneousMultifidelityGP, compute_w_gmm\n",
    "from jaxbo.test_functions import *\n",
    "\n",
    "from jax.scipy.stats import norm\n",
    "import jaxbo.acquisitions as acquisitions\n",
    "\n",
    "from jaxbo.input_priors import uniform_prior, gaussian_prior\n",
    "\n",
    "\n",
    "onp.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example from \n",
    "# https://asmedigitalcollection.asme.org/mechanicaldesign/article/141/12/121001/975244?casa_token=45A-r7iV9IUAAAAA:ji-aHZ_T_HQ5Q1xgNxloqrG2LjOpFkXMItdWnuGH9d02MysONc3VTfrtM8GSB5oTdE2jcQ\n",
    "# Section 4, and constraint in section 4.2 \n",
    "\n",
    "\n",
    "def f_H(x):\n",
    "    x1, x2 = x[0], x[1]\n",
    "    a = 1.0\n",
    "    b = 5.1 / (4*np.pi**2)\n",
    "    c = 5 / np.pi\n",
    "    r = 6\n",
    "    s = 10\n",
    "    t = 1 / (8*np.pi)\n",
    "    f = a * (x2 - b*x1**2 + c*x1 -r)**2 + s * (1-t) * np.cos(x1) + s\n",
    "    return f\n",
    "\n",
    "def f_L(x):\n",
    "    x1, x2 = x[0], x[1]\n",
    "    f = 10*np.sqrt(f_H(x - 2)) + 2*(x1 - 2.5) - 3*(3*x2 - 7) - 1 # from the paper\n",
    "    return f\n",
    "\n",
    "def constraint(x):\n",
    "    x1, x2 = (x[0]-2.5)/7.5, (x[1] - 7.5)/7.5\n",
    "    g1 = (4 - 2.1*x1**2 + 1./3*x1**4)*x1**2 + x1*x2 + (-4+4*x2**2)*x2**2 + 3*np.sin(6*(1-x1)) + 3*np.sin(6*(1-x2))\n",
    "    return g1 - 6.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of the problem\n",
    "dim = 2\n",
    "\n",
    "# Boundary of the domain\n",
    "lb = np.array([-5.0, 0.0])\n",
    "ub = np.array([10.0, 15.0])\n",
    "\n",
    "bounds = {'lb': lb, 'ub': ub}\n",
    "\n",
    "# Visualization of the function and constraints in 2D grid\n",
    "nn = 100\n",
    "xx = np.linspace(lb[0], ub[0], nn)\n",
    "yy = np.linspace(lb[1], ub[1], nn)\n",
    "XX, YY = np.meshgrid(xx, yy)\n",
    "X_star = np.concatenate([XX.flatten()[:,None], \n",
    "                         YY.flatten()[:,None]], axis = 1)\n",
    "\n",
    "\n",
    "y_f_H_star = vmap(f_H)(X_star)\n",
    "y_f_L_star = vmap(f_L)(X_star)\n",
    "y_c_H_star = vmap(constraint)(X_star)\n",
    "y_c_L_star = vmap(constraint)(X_star)\n",
    "\n",
    "Y_f_H_star = griddata(onp.array(X_star), onp.array(y_f_H_star), (onp.array(XX), onp.array(YY)), method='cubic')\n",
    "Y_f_L_star = griddata(onp.array(X_star), onp.array(y_f_L_star), (onp.array(XX), onp.array(YY)), method='cubic')\n",
    "Y_c_H_star = griddata(onp.array(X_star), onp.array(y_c_H_star), (onp.array(XX), onp.array(YY)), method='cubic')\n",
    "Y_c_L_star = griddata(onp.array(X_star), onp.array(y_c_L_star), (onp.array(XX), onp.array(YY)), method='cubic')\n",
    "\n",
    "\n",
    "plt.figure(figsize = (10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "fig = plt.contourf(XX, YY, Y_f_H_star)\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title(r'High fidelity objective')\n",
    "plt.colorbar(fig)\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "fig = plt.contourf(XX, YY, Y_c_H_star)\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title(r'High fidelity constraint')\n",
    "plt.colorbar(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the feasible domain and the location of the best value of this problem\n",
    "\n",
    "judge1 = (y_c_H_star >= 0)\n",
    "\n",
    "total_judge = judge1 \n",
    "\n",
    "valid_index = np.where(total_judge)\n",
    "#print(valid_index)\n",
    "\n",
    "valid_x = X_star[valid_index]\n",
    "valid_y = y_f_H_star[valid_index]\n",
    "\n",
    "#print(valid_x.shape, valid_y.shape)\n",
    "idx_best = np.argmin(valid_y)\n",
    "x_best = valid_x[idx_best]\n",
    "y_best = valid_y[idx_best]\n",
    "\n",
    "plt.figure(figsize = (6,4))\n",
    "fig = plt.contourf(XX, YY, Y_f_H_star)\n",
    "plt.plot(valid_x[:,0], valid_x[:, 1], 'r.', markersize = 2.)\n",
    "plt.plot(x_best[0], x_best[1], 'y.', markersize = 8.)\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title(r'High fidelity objective')\n",
    "plt.colorbar(fig)\n",
    "\n",
    "print(\"best y\", y_best, \"best x\", x_best)\n",
    "\n",
    "true_x = x_best\n",
    "true_y = y_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem settings\n",
    "\n",
    "# Number of initial data for objective and constraints\n",
    "N_H_f = 5\n",
    "N_c = 40\n",
    "N_L_f = 40\n",
    "\n",
    "noise_f = 0.00\n",
    "noise_c = 0.00\n",
    "\n",
    "# The input layer is the dimention of the low fidelity input, \n",
    "# The output layer is the dimention of the high fidelity input. \n",
    "# The intermediate layer is arbitrary.\n",
    "layers = [1, 10, 2]\n",
    "\n",
    "# Define prior distribution\n",
    "p_x = uniform_prior(lb, ub)\n",
    "\n",
    "# JAX-BO setting\n",
    "options = {'kernel': 'RBF',\n",
    "           'input_prior': p_x,\n",
    "           'constrained_criterion': 'LW_LCBC',\n",
    "           'criterion': 'US',\n",
    "           'kappa': 2.0,\n",
    "           'nIter': 20}\n",
    "\n",
    "\n",
    "gp_model = MultipleIndependentHeterogeneousMFGP(options, layers)\n",
    "\n",
    "# Domain bounds (already defined before where we visualized the data)\n",
    "bounds = {'lb': lb, 'ub': ub}\n",
    "\n",
    "# Initial training data for objectives\n",
    "X_f_H = lb + (ub-lb)*lhs(dim, N_H_f)\n",
    "y_f_H = vmap(f_H)(X_f_H)\n",
    "y_f_H = y_f_H + noise_f*y_f_H_star.std(0)*onp.random.normal(0, 1, size=y_f_H.shape)\n",
    "\n",
    "\n",
    "X_f_L = lb + (ub-lb)*lhs(dim, N_L_f)\n",
    "y_f_L = vmap(f_L)(X_f_L)\n",
    "y_f_L = y_f_L + noise_f*y_f_L_star.std(0)*onp.random.normal(0, 1, size=y_f_L.shape)\n",
    "\n",
    "# Deliberately remove last dimension from low fidelity input data\n",
    "X_f_L = X_f_L[:,:-1]\n",
    "\n",
    "# Initial training data for constraints\n",
    "X_c_H = lb + (ub-lb)*lhs(dim, N_c)\n",
    "y_c_H = vmap(constraint)(X_c_H)\n",
    "y_c_H = y_c_H + noise_c*y_c_H_star.std(0)*onp.random.normal(0, 1, size=y_c_H.shape)\n",
    "\n",
    "X_c_L = np.array(X_c_H)\n",
    "y_c_L = np.array(y_c_H)\n",
    "\n",
    "# Deliberately remove last dimension from low fidelity constraint (this should be consistent with the low fidelity input)\n",
    "X_c_L = X_c_L[:,:-1]\n",
    "\n",
    "\n",
    "# Visualize the initial data for objective and constraints\n",
    "plt.figure(figsize = (10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "fig = plt.contourf(XX, YY, Y_f_H_star)\n",
    "plt.plot(X_f_H[:,0], X_f_H[:,1], 'ro', label = \"Initial high fideilty objective data\")\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title(r'High fidelity objective')\n",
    "plt.colorbar(fig)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "fig = plt.contourf(XX, YY, Y_c_H_star)\n",
    "plt.plot(X_c_H[:,0], X_c_H[:,1], 'bo', label = \"Initial high fidelity constraint data\")\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title(r'High fidelity constraint')\n",
    "plt.colorbar(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Bayesian optimization loop\n",
    "rng_key = random.PRNGKey(0)\n",
    "for it in range(options['nIter']):\n",
    "    print('-------------------------------------------------------------------')\n",
    "    print('------------------------- Iteration %d/%d -------------------------' % (it+1, options['nIter']))\n",
    "    print('-------------------------------------------------------------------')\n",
    "\n",
    "    # Fetch normalized training data\n",
    "    norm_batch_f, norm_const_f = normalize_HeterogeneousMultifidelityGP(X_f_L, y_f_L, X_f_H, y_f_H, bounds)\n",
    "    norm_batch_c, norm_const_c = normalize_HeterogeneousMultifidelityGP(X_c_L, y_c_L, X_c_H, y_c_H, bounds)\n",
    "    \n",
    "    # Define a list using the normalized data and the normalizing constants\n",
    "    norm_batch_list = [norm_batch_f, norm_batch_c]\n",
    "    norm_const_list = [norm_const_f, norm_const_c]\n",
    "    \n",
    "    # Train GP model with 100 random restart\n",
    "    print('Train GP...')\n",
    "    rng_key = random.split(rng_key)[0]\n",
    "    opt_params_list = gp_model.train(norm_batch_list,\n",
    "                                     rng_key,\n",
    "                                     num_restarts = 10)\n",
    "\n",
    "    # Fit GMM\n",
    "    if options['constrained_criterion'] == 'LW_LCBC':\n",
    "        print('Fit GMM...')\n",
    "        rng_key = random.split(rng_key)[0]\n",
    "        kwargs = {'params': opt_params_list,\n",
    "                  'batch': norm_batch_list,\n",
    "                  'norm_const': norm_const_list,\n",
    "                  'bounds': bounds,\n",
    "                  'rng_key': rng_key}\n",
    "        gmm_vars = gp_model.fit_gmm(**kwargs, N_samples = 10000)\n",
    "    else:\n",
    "        gmm_vars = None\n",
    "\n",
    "\n",
    "    # Find the next acquisition point with 50 random restart\n",
    "    print('Computing next acquisition point (objective)...')\n",
    "    kwargs = {'params': opt_params_list,\n",
    "              'batch': norm_batch_list,\n",
    "              'norm_const': norm_const_list,\n",
    "              'bounds': bounds,\n",
    "              'kappa': options['kappa'],\n",
    "              'gmm_vars': gmm_vars,\n",
    "              'rng_key': rng_key}\n",
    "    # Acquire data\n",
    "    new_X_f_H,_,_ = gp_model.constrained_compute_next_point_lbfgs(num_restarts=50, **kwargs)\n",
    "    new_y_f_H = vmap(f_H)(new_X_f_H) # This is the output of the solver for generating the objective function\n",
    "    new_y_f_H = new_y_f_H + noise_f*y_f_H_star.std(0)*onp.random.normal(new_y_f_H.shape)\n",
    "\n",
    "    # Find the next acquisition point with 50 random restart\n",
    "    print('Computing next acquisition point (constraint)...')\n",
    "    kwargs = {'params': opt_params_list[-1],\n",
    "              'batch': norm_batch_list[-1],\n",
    "              'norm_const': norm_const_list[-1],\n",
    "              'bounds': bounds,\n",
    "              'rng_key': rng_key}\n",
    "    # Acquire data\n",
    "    new_X_c_H,_,_ = gp_model.compute_next_point_lbfgs(num_restarts=50, **kwargs)\n",
    "    new_y_c_H = vmap(constraint)(new_X_c_H) # This is the output of the solver for generating the constraint1 functions\n",
    "    new_y_c_H = new_y_c_H + noise_c*y_c_H_star.std(0)*onp.random.normal(new_y_c_H.shape)\n",
    "\n",
    "    # # Augment training data\n",
    "    print('Updating data-set...')\n",
    "    X_f_H = np.concatenate([X_f_H, new_X_f_H], axis = 0)\n",
    "    X_c_H = np.concatenate([X_c_H, new_X_c_H], axis = 0)\n",
    "    \n",
    "    # In order to make the model work, we remove last dimension from low fidelity constraint (input dimention match the low fidelity inputs)\n",
    "    X_c_L = np.array(X_c_H[:,:-1])\n",
    "\n",
    "    y_f_H = np.concatenate([y_f_H, new_y_f_H], axis = 0)\n",
    "    y_c_H = np.concatenate([y_c_H, new_y_c_H], axis = 0)\n",
    "    y_c_L = np.array(y_c_H)\n",
    "\n",
    "    # # Print current best\n",
    "    print('True location: ({}), True value: {}'.format(true_x, true_y))\n",
    "    print('New  location: ({}), New  value: {}'.format(new_X_f_H, new_y_f_H))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the final outputs \n",
    "\n",
    "kwargs = {'params': opt_params_list,\n",
    "          'batch': norm_batch_list,\n",
    "          'norm_const': norm_const_list,\n",
    "          'bounds': bounds,\n",
    "          'kappa': gp_model.options['kappa'],\n",
    "          'rng_key': rng_key,\n",
    "          'gmm_vars': gmm_vars}\n",
    "\n",
    "# Making prediction on the posterior objective and all constraints\n",
    "mean, std = gp_model.predict_all(X_star, **kwargs)\n",
    "\n",
    "mean = onp.array(mean)\n",
    "std = onp.array(std)\n",
    "\n",
    "mean[0:1,:] = mean[0:1,:] * norm_const_list[0]['sigma_y'] + norm_const_list[0]['mu_y']\n",
    "std[0:1,:] = std[0:1,:] * norm_const_list[0]['sigma_y']\n",
    "\n",
    "\n",
    "# Compute the weight\n",
    "if options['constrained_criterion'] == 'LW_LCBC':\n",
    "    w_pred = compute_w_gmm(X_star, **kwargs)\n",
    "    \n",
    "\n",
    "# Compute the upper and lower bounds of the posterior distributions\n",
    "lower = mean - 2.0*std\n",
    "upper = mean + 2.0*std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the acquisition function\n",
    "acq_fn1 = lambda x: gp_model.constrained_acquisition(x, **kwargs)\n",
    "LW_LCBCacq = vmap(acq_fn1)(X_star)\n",
    "\n",
    "# Compute the ratio and weights derived by the constraints and convert everything into numpy for plotting\n",
    "ratio1 = mean[1,:] / std[1,:]\n",
    "\n",
    "weight1 = norm.cdf(mean[1,:]/std[1,:])\n",
    "\n",
    "LW_LCBCacq = onp.array(LW_LCBCacq)\n",
    "\n",
    "mean = onp.array(mean)\n",
    "std = onp.array(std)\n",
    "\n",
    "ratio1 = onp.array(ratio1)\n",
    "\n",
    "weight1 = onp.array(weight1)\n",
    "\n",
    "y_f_H_pred = onp.array(mean[0,:])\n",
    "y_c_H_pred = onp.array(mean[1,:])\n",
    "\n",
    "y_f_H_std = onp.array(std[0,:])\n",
    "\n",
    "try:\n",
    "    w_pred = onp.array(w_pred)\n",
    "except:\n",
    "    w_pred = onp.ones_like(y_f_H_std)\n",
    "    \n",
    "\n",
    "kappa = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numpy variable into grid data for visualization\n",
    "Y_f_H_pred = griddata(onp.array(X_star), y_f_H_pred, (onp.array(XX), onp.array(YY)), method='cubic')\n",
    "Y_c_H_pred = griddata(onp.array(X_star), y_c_H_pred, (onp.array(XX), onp.array(YY)), method='cubic')\n",
    "\n",
    "Y_f_H_std = griddata(onp.array(X_star), y_f_H_std, (onp.array(XX), onp.array(YY)), method='cubic')\n",
    "\n",
    "Ratio1 = griddata(onp.array(X_star), ratio1, (onp.array(XX), onp.array(YY)), method='cubic')\n",
    "\n",
    "Weight1 = griddata(onp.array(X_star), weight1, (onp.array(XX), onp.array(YY)), method='cubic')\n",
    "\n",
    "LW_LCBCacq = griddata(onp.array(X_star), LW_LCBCacq.flatten(), (onp.array(XX), onp.array(YY)), method='cubic')\n",
    "\n",
    "W_pred = griddata(onp.array(X_star), w_pred.flatten(), (onp.array(XX), onp.array(YY)), method='cubic')\n",
    "\n",
    "\n",
    "\n",
    "LCBacq = Y_f_H_pred - 3. - kappa*Y_f_H_std\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize = (16,10))\n",
    "plt.subplot(2, 4, 1)\n",
    "fig = plt.contourf(XX, YY, Y_c_H_star)\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title(r'Exact constraint1')\n",
    "plt.colorbar(fig)\n",
    "\n",
    "plt.subplot(2, 4, 2)\n",
    "fig = plt.contourf(XX, YY, Y_c_H_pred)\n",
    "plt.plot(X_c_H[:,0], X_c_H[:,1], 'r.')\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title(r'Pred constraint1')\n",
    "plt.colorbar(fig)\n",
    "\n",
    "plt.subplot(2, 4, 3)\n",
    "fig = plt.contourf(XX, YY, Ratio1)\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title(r'Ratio1')\n",
    "plt.colorbar(fig)\n",
    "\n",
    "\n",
    "plt.subplot(2, 4, 4)\n",
    "fig = plt.contourf(XX, YY, np.clip(Weight1, 0, np.inf))\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title(r'Weight1')\n",
    "plt.colorbar(fig)\n",
    "\n",
    "\n",
    "plt.subplot(2, 4, 5)\n",
    "fig = plt.contourf(XX, YY, Y_f_H_star)\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title(r'Exact objective')\n",
    "plt.colorbar(fig)\n",
    "\n",
    "plt.subplot(2, 4, 6)\n",
    "fig = plt.contourf(XX, YY, Y_f_H_pred)\n",
    "plt.plot(X_f_H[:,0], X_f_H[:,1], 'r.')\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title(r'Pred objective')\n",
    "plt.colorbar(fig)\n",
    "\n",
    "plt.subplot(2, 4, 7)\n",
    "fig = plt.contourf(XX, YY, LCBacq)\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title(r'LCB')\n",
    "plt.colorbar(fig)\n",
    "\n",
    "\n",
    "plt.subplot(2, 4, 8)\n",
    "fig = plt.contourf(XX, YY, LW_LCBCacq)\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title(r'LW_LCBC')\n",
    "plt.colorbar(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data we collected and the ground truth\n",
    "plt.figure(figsize = (15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "fig = plt.contourf(XX, YY, Y_f_H_star)\n",
    "plt.plot(valid_x[:,0], valid_x[:, 1], 'r.', markersize = 2.)\n",
    "plt.plot(true_x[0], true_x[1], 'k.', markersize = 10.)\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title(r'Exact objective')\n",
    "plt.colorbar(fig)\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "fig = plt.contourf(XX, YY, Y_f_H_pred)\n",
    "plt.plot(X_f_H[:,0], X_f_H[:,1], 'r.')\n",
    "plt.plot(true_x[0], true_x[1], 'k.', markersize = 10.)\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title(r'Pred objective')\n",
    "plt.colorbar(fig)\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "fig = plt.contourf(XX, YY, W_pred)\n",
    "plt.plot(X_f_H[:,0], X_f_H[:,1], 'r.')\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$')\n",
    "plt.title(r'Pred output weight')\n",
    "plt.colorbar(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
